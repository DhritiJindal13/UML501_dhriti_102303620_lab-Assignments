{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06ed51ca",
   "metadata": {},
   "source": [
    "## Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6111993e",
   "metadata": {},
   "source": [
    "Q1 Write a Python program to scrape all available books from the website (https://books.toscrape.com/) Books to Scrape – a live site built for practicing scraping (safe, legal, no anti-bot). For each book, extract the following details:\n",
    "1. Title\n",
    "2. Price\n",
    "3. Availability (In stock / Out of stock)\n",
    "4. Star Rating (One, Two, Three, Four, Five)\n",
    "Store the scraped results into a Pandas DataFrame and export them to a CSV file named books.csv.\n",
    "(Note: Use the requests library to fetch the HTML page. Use BeautifulSoup to parse and extract book details and handle pagination so that books from all pages are scraped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b43bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 1000 books. Data saved to books.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "def get_star_rating(tag):\n",
    "    # Extract star rating as text (One, Two, Three, Four, Five).\n",
    "    classes = tag.get(\"class\", [])\n",
    "    ratings = [\"One\", \"Two\", \"Three\", \"Four\", \"Five\"]\n",
    "    for r in ratings:\n",
    "        if r in classes:\n",
    "            return r\n",
    "    return None\n",
    "\n",
    "books = []\n",
    "page = 1\n",
    "\n",
    "while True:\n",
    "    url = BASE_URL.format(page)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        break  # No more pages\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    articles = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    \n",
    "    if not articles:\n",
    "        break  # No books found on this page\n",
    "    \n",
    "    for article in articles:\n",
    "        title = article.h3.a[\"title\"]\n",
    "        price = article.find(\"p\", class_=\"price_color\").text.strip()\n",
    "        availability = article.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "        star_rating = get_star_rating(article.find(\"p\", class_=\"star-rating\"))\n",
    "        \n",
    "        books.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Availability\": availability,\n",
    "            \"Star Rating\": star_rating\n",
    "        })\n",
    "    \n",
    "    page += 1\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(books)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "print(f\"Scraped {len(df)} books. Data saved to books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda60885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Star Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>Â£51.77</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>Â£53.74</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>Â£50.10</td>\n",
       "      <td>In stock</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>Â£54.23</td>\n",
       "      <td>In stock</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title    Price Availability Star Rating\n",
       "0                   A Light in the Attic  Â£51.77     In stock       Three\n",
       "1                     Tipping the Velvet  Â£53.74     In stock         One\n",
       "2                             Soumission  Â£50.10     In stock         One\n",
       "3                          Sharp Objects  Â£47.82     In stock        Four\n",
       "4  Sapiens: A Brief History of Humankind  Â£54.23     In stock        Five"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec352c",
   "metadata": {},
   "source": [
    "Q2. Write a Python program to scrape the IMDB Top 250 Movies list (https://www.imdb.com/chart/top/) . For each movie, extract the following details:\n",
    "1. Rank (1–250)\n",
    "2. Movie Title\n",
    "3. Year of Release\n",
    "4. IMDB Rating\n",
    "Store the results in a Pandas DataFrame and export it to a CSV file named imdb_top250.csv.\n",
    "(Note: Use Selenium/Playwright to scrape the required details from this website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f79d57ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 250 movies and saved to imdb_top250.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Setup Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--headless\")  \n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "url = \"https://www.imdb.com/chart/top/\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait until the list is visible\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.ipc-metadata-list-summary-item\"))\n",
    ")\n",
    "\n",
    "movies = driver.find_elements(By.CSS_SELECTOR, \"li.ipc-metadata-list-summary-item\")\n",
    "\n",
    "all_movies = []\n",
    "\n",
    "for rank, movie in enumerate(movies, start=1):\n",
    "    try:\n",
    "        # Title\n",
    "        title = movie.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\").text.strip()\n",
    "\n",
    "        # Year (first <span> inside metadata block)\n",
    "        metadata_spans = movie.find_elements(By.CSS_SELECTOR, \"div.cli-title-metadata span\")\n",
    "        year = metadata_spans[0].text if metadata_spans else \"N/A\"\n",
    "\n",
    "        # Rating\n",
    "        rating = movie.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star--rating\").text.strip()\n",
    "\n",
    "        all_movies.append({\n",
    "            \"Rank\": rank,\n",
    "            \"Title\": title,\n",
    "            \"Year\": year,\n",
    "            \"IMDB Rating\": rating\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping movie #{rank} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(all_movies)\n",
    "df.to_csv(\"imdb_top250.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Scraped {len(df)} movies and saved to imdb_top250.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b19c25c",
   "metadata": {},
   "source": [
    "Q3. Write a Python program to scrape the weather information for top world cities from the given website (https://www.timeanddate.com/weather/) . For each city, extract the following details:\n",
    "1. City Name\n",
    "2. Temperature\n",
    "3. Weather Condition (e.g., Clear, Cloudy, Rainy, etc.)\n",
    "Store the results in a Pandas DataFrame and export it to a CSV file named weather.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3a690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping of 140 cities done. Data saved to weather.csv\n",
      "             City                Condition Temperature\n",
      "0           Accra  Scattered clouds. Warm.       27 °C\n",
      "1      Edmonton *             Sunny. Mild.       17 °C\n",
      "2        Nassau *      Broken clouds. Hot.       32 °C\n",
      "3     Addis Ababa    Passing clouds. Cool.       16 °C\n",
      "4     Frankfurt *     Broken clouds. Mild.       17 °C\n",
      "5       New Delhi               Fog. Warm.       31 °C\n",
      "6        Adelaide              Quite cool.       12 °C\n",
      "7  Guatemala City     Broken clouds. Mild.       23 °C\n",
      "8   New Orleans *             Sunny. Warm.       29 °C\n",
      "9         Algiers          Overcast. Warm.       26 °C\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "# Setup Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")   # remove if you want to see browser\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "driver.get(\"https://www.timeanddate.com/weather/\")\n",
    "WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"table.zebra.fw.tb-theme\"))\n",
    ")\n",
    "\n",
    "# Get the table\n",
    "table = driver.find_element(By.CSS_SELECTOR, \"table.zebra.fw.tb-theme\")\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "cities, conditions, temps = [], [], []\n",
    "\n",
    "for row in rows[1:]:   # skip header\n",
    "    cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    if not cols:\n",
    "        continue\n",
    "\n",
    "    # each city is 4 cols: city, time, condition(icon), temperature\n",
    "    for i in range(0, len(cols), 4):\n",
    "        if i + 3 >= len(cols):\n",
    "            continue\n",
    "\n",
    "        city = cols[i].text.strip()\n",
    "\n",
    "        cond_cell = cols[i+2]\n",
    "        condition = \"N/A\"\n",
    "        try:\n",
    "            img = cond_cell.find_element(By.TAG_NAME, \"img\")\n",
    "            condition = img.get_attribute(\"alt\") or img.get_attribute(\"title\")\n",
    "        except:\n",
    "            if cond_cell.text.strip():\n",
    "                condition = cond_cell.text.strip()\n",
    "\n",
    "        temp = cols[i+3].text.strip()\n",
    "\n",
    "        if city:\n",
    "            cities.append(city)\n",
    "            conditions.append(condition)\n",
    "            temps.append(temp)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"City\": cities,\n",
    "    \"Condition\": conditions,\n",
    "    \"Temperature\": temps\n",
    "})\n",
    "\n",
    "print(f\"Scraping of {len(df)} cities done. Data saved to weather.csv\")\n",
    "print(df.head(10))\n",
    "df.to_csv(\"weather.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
